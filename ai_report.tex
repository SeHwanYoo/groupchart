\documentclass[a4paper, 12pt]{report}

\title{AI and AI programming Assignment}\\

\begin{document}
\maketitle
\begin{flushright}
  Subject: Computer Vision, Robotics and Machine Learning\\
  Student ID: 655\\
  Name: Sehwan Yoo
\end{flushright}
\cleardoublepage

\section*{EXECUSIVE SUMMARY}
  The concept of neural network model showed in 1943 by Warren McCurloch and Walter Pitts with reference to the structure of biological neurons, and it has significantly shown to solve problems such as recognition, estimation, classification and analysing. Artificial neural network 
  
  The aim of this paper is to understand Neural Network via MATLAB project with discuss and analyse the results. It used neural network simulation which basically supports cancer dataset 
  
The artificial neural network is the aspect that this experiment
focus on. Artificial neural networks are simply a mathematical algorithm model that is
based on a biological neural network. It mainly implements functions such as
approximate estimation of functions through a large number of calculations. The
artificial nervous system structure is like the biological central nervous system. . Many
neuron models are built through the system to imitate the processing mode of the
biological nervous system, and the system can be self-adaptive through repeated
mechanical learning and pattern recognition of the input. Neural networks are widely
used in various fields, such as large complex control systems, especially in artificial
intelligence.

This experiment mainly studies the influence of some parameter settings on the training
results in neural network training, including nodes, epochs and the number of individual
classifiers. In the neural network training model, the training mode is first determined.
First, the ‘trainscg’ mode is selected, in which the effects of nodes and epochs on the
training results are studied. It can be seen from the experimental results that when one
of the parameters of nodes and epochs is set to be low, the error rate generated by the
training result will be significantly improved, which will affect the training effect.
1Therefore, in order to improve the results of the training, you should experiment to find
the appropriate size of the nodes and epochs settings. The effect of the number of
classifiers on the training effect was then studied. According to the data analysis of the
experimental results, when using multiple classifiers to train the neural network, the
effect is better than that of the single classifier. However, when there are too many
classifiers, it has its drawbacks. That is, as the number of classifiers increases, the
amount of calculations also increases, making the program operation time too long.
Finally, the experiment explores the training effects under different training modes. In
the experiment, three training methods, ‘trainscg’, ‘trainlm’ and ‘trainrp’, were mainly
selected. All three training methods have their own distinctive characteristics and
advantages and disadvantages. Among them, ‘trainscg’ is the most memory-saving
compared to the other two training methods. And ‘trainlm’ can avoid a lot of
calculations and thus reduce training time, so it is the fastest of the three methods, but
it requires a lot of memory to support. Besides, ‘trainrp’ is the best training, it has the
lowest error rate, which is conducive to complex training.
\cleardoublepage

\section*{INTRODUCTION}
Neural Network (NN) is technique to recognize images and signal processing. The basic concept of NN is to use connected nodes, and learn via training, test and validation process with datasets. It is able to improve itself through weights and bias. When NN learn from dataset, weight values are adjusted for improving accuracy and performance. According to these experiments, how the system is affected by parameters, different factors and NN models, and find optimal parameters and best values. All of experiments will be analyzed by comparison error rates and execution times. The all of experiments 1, 2 and 3 used cancer dataset which is basic dataset.

 %%%%%%%%%%%%%%%%
Neural networks are usually divided into two categories: biological neural network and
artificial neural network. Biological neural network generally refers to the structure and
the network which consists of neurons and cells in the brain. Besides, artificial neural
networks is a kind of Mathematical algorithm model. Its original design was inspired
by the imitation of the animal's nervous system. It runs primarily through a large
number of inputs and a series of unknown approximation functions. In an artificial
neural network, its structure is like the central nervous system of an animal, with
connected 'neurons'. It can perform a large number of machine learning and pattern
recognition through input to realize an adaptive system. This artificial neural network
system has a wide range of applications. The application system built by artificial neural
network can accomplish many functions, such as supporting complex control system
and artificial intelligence and so on. This experiment mainly carried out the simulation
of neural network, selected the cancer dataset for training, and analyzed the training
results in detail. In the neural network, there are various training algorithms for this
experiment, including trainscg, trainlm, trainrp, etc. The purpose of this experiment is
to analyze and compare the data results through a large number of repeated experiments,
so as to explore which training algorithm is more suitable for this experiment. Next,
this paper will describe the experimental process and results, and then compare and
analyze the experimental data to get the final experimental conclusion.

\section*{Experiments}
  This section shows experiments' setting and results in R2019a environment. 

\subsection*{Experiment 1}
This experiment used cancer datasets, and repeated 30 times each sets of training and test. Test and train sets’ rate were 50/50% without validation data, and epochs were [4 8 16 32 64] with nodes = [2 8 32]. 

These experiment is to study the influence of nodes and epoches. Cancer dataset is used
in this neural network experiment. First of all, set the training algorithm as ‘trainscg’.
Then set the nodes=[2,8,32] and epochs=[4,8,16,32,64]. In addition, random train is set
as 50%, test split is set as 50% and validation set is 0. These program need to be repeated
at least 30 times which can be used to calculate the average result. The result of this
part is shown in the following Figure 1 and Figure 2.
As we can see in Figure 1, it shows the relationship between train/test error rate and
epochs when the number of nodes is different. With the increase of epochs, train error
rate will decrease but the lowest test error rate happened when nodes=8 and when the
number of nodes is lager than 8, test error rate will increase. In addition, train perform
better an better when node increase, because the train error rate will decrease. Besides,
in all of plots, setting nodes=32 and epochs=64 makes the training has best performance. In figure 2, it shows the different standard deviation as node-epoch changes. When the
nodes is set as 32, it has lowest std which means that this setting makes the training
stable. So, nodes equal to 32 is the best choice of this training. Besides, all of the test
std becoming to overlap with the increase of epochs. Overall, nodes=32 and epochs=64 is an appropriate value of this training.

\subsection*{Experiment 2}
(1) Experiment setting
In this experiment, it was implemented via previous experiment, collecting test and training data using experiment 1 code. Then, it changed classifiers that is odd number (3 ~ 25), and adapted Majority vote for error rates. 

(2) Experiment result This experiment’s result showed the network performance using odd numbers’ classification. The best performance of training set is 0.0172 at number 7, and 0.0200 is the smallest error rates for test set.

Figure 4. Adopted multi classification of training and test Classifiers Training sets Test sets 3 0.0430 0.0200 5 0.0315 0.0457 7 0.0172 0.0400 9 0.0201 0.0400 11 0.0344 0.0257 13 0.0201 0.0343 15 0.0287 0.0286 17 0.0315 0.0229 19 0.0229 0.0371 21 0.0229 0.0343 23 0.0258 0.0257 25 0.0258 0.0229 

Table 3. Error rates of training and test sets of majority vote According to the result, training sets showed similar performance because of rounding process of Majority vote. 
 %%%%%%%%%%%%%%%%
This experiment 2 is designed to explore the influence of the number of classifiers on
training performance. The training performance with individual performance has been
shown in Exp1, and what need to be done is explore the performance with ensemble
accuracy. As Exp1, setting the nodes=[2,8,32] and epochs=[4,8,16,32,64]. In addition,
random train is set as 50%, test split is set as 50% and validation set is 0. Besides, the
5number of classifier is selected as[3,15,25] with random starting weight and Majority
Vote to see
whether the performance inprove . Then, compare the result of different
number of classifiers which is shown in following figures.
From Figure 3, we can see that the train and test error rate will decrase with the rise of
number of classifiers, which means that using ensemble of classifiers can inprove the
poformance of training and it is beter than individual one. In Figure 4, it present the train std and the test std as the numberof individual calssifiers
changing. As we can see that, With the increase of a, the value of b becomes smaller
and smaller, which means that the increase of a will make the training performance of
the system more stable. In Figure 5 and Figure 6, they show the training porformance when change the
classifiers in 3,15 and 25. As we can see in Figure 5, When more and more classifiers
are set, the error rate in training is obviously smaller and smaller. Then, the same
analysis results can be obtained by comparing the results when classifier is set as 1 in
Figure 1.
In addition, Figure 6 shows the std performance as epochs change in three
different numbers of classifiers. Comparing to Figure 2, as we can see, the data is
similar when number of classifiers is set as 1 and 3 as well as 15 and 25. This means
that the effect of the number of classifiers on the STD is not significant, unless the
number of classifiers is very different, the STD is very similar . In conclusion, the effect of using multiple classifiers is better than that of using a single
classifier, and the more classifiers, the fewer errors will be generated.



\subsection*{Experiment 3}
  

\section*{conclusion} 
  The project implemented neural network with different epochs, nodes and function types. The network could be trained overfitting and underfitting by epochs, and nodes able to corrupt unstable system. However, it shows how to improve performance of network via changing parameters, but the system might have a problem it really needs to consider.

 %%%%%%%%%%%%%%%%
 All in All, this experiment conducted a research on the neural network model through
MATLAB software, and the cancer dataset was selected as the experimental setting.The
experiment mainly explored three aspects:1. Influence of Settings of epochs and nodes
on experimental results. 2. Influence of preset number of classifiers on training results.
3. Comparison of training results of three different training algorithms.
The choice of Epochs and nodes is not that larger is better or less is better, but based on
the comparison of experimental results. Under the 'trainscg' algorithm in this
experiment, the experimental results are that when Epochs =64 and nodes=32 are the
most appropriate Settings.
Then, the number of classifiers was adjusted, and the training results were compared in
10the four cases where the number of classifiers was 1,3,15, and 25, respectively. Finally,
the train error rate would decrease with the increase of the number of classifiers, that is,
the better the training effect. However, it is worth mentioning that with the increase of
the number of classifiers, the amount of calculation will increase greatly, resulting in
the increase of program operation time.
Finally, the training effects of the three training methods were explored. By analyzing
the train/test error rate and standard deviation set by a single classifier and multiple
classifiers, the conclusion was obtained. The best performance of the three algorithms
was' trainlm '.

\cleardoublepage

% \section*{Reference}
\begin{thebibliography}{9}
\bibitem{latexcompanion} 
Michel Goossens, Frank Mittelbach, and Alexander Samarin. 
\textit{The \LaTeX\ Companion}. 
Addison-Wesley, Reading, Massachusetts, 1993.
 
\bibitem{einstein} 
Albert Einstein. 
\textit{Zur Elektrodynamik bewegter K{\"o}rper}. (German) 
[\textit{On the electrodynamics of moving bodies}]. 
Annalen der Physik, 322(10):891–921, 1905.
 
\bibitem{knuthwebsite} 
Knuth: Computers and Typesetting,
\\\texttt{http://www-cs-faculty.stanford.edu/\~{}uno/abcde.html}
\end{thebibliography}

\cleardoublepage

\section*{Appendix}
\subsection*{Experiment 1}
dw
\subsection*{Experiment 2}
dw
\subsection*{Experiment 3}
wdwd


\end{document}